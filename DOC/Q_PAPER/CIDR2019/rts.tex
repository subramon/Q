\section{Q's Run Time System}

Q is a high-performance ``almost-relational'' 
analytical, single-node, column-store database. 
\be
\item 
By ``analytical'' we mean that data changes at the user's behest (e.g.
loading a data set) but is not subject to external events.
\item 
By ``almost-relational'' we mean that it would more correctly
be called a ``tabular model'' \cite{Codd1982}. As Codd states, ``Tables are
at a lower level of abstraction than relations, since they give
the impression that positional (array-type) addressing is applicable
(which is not true of \(n\)-ary relations), and they fail to
show that the information content of a table is independent
of row order. Nevertheless, even with these minor flaws,
tables are the most important conceptual representation of
relations, because they are universally understood.''
\item By ``single-node'', we mean that Q does not distribute computation across
  machines. The flow of execution is inherently single-threaded. However,
  OpenMP is heavily used {\em within} individual operations so as
  to exploit multi-core systems as well as GPUs.
\item By ``column-store'', we mean that 
Q provides the Lua programmer with the Vector type, each
individual element of which is a Scalar. A table in Q is a Lua
table of Vectors (Section~\ref{vectors_versus_tables}), where a Lua table is an
associative array, like a Python dictionary.

\ee

\subsection{Q as a Lua extension}


It is useful to think of Q as a domain specific language, targeted for data
manipulation. In contrast with Wevers' work \cite{Wevers2014} on
developing a persistent functional language with
a relational database system inside, Q works within the context of Lua, while
inspired by functional programming ideas like memo-ization, lazy evaluation,
etc.
More accurately, Q is a C library, embedded within an interpreted
language.
We chose to embed within an existing language because (i) we did not have to
write a custom compiler (ii) it allowed us to leverage a rich eco-system of
libraries, debuggers, web development environments, allowing the programmer to
blur the distinction between application logic and database programming.

We chose Lua
because it was designed specifically as both an embedding and embedded language
\cite{Lua2011} and it had a wickedly fast interpreter, LuaJIT.
We experimented with several approaches to invoking C from Lua. These included
(a) dyncall \cite{Adler2013} (b) the native Lua C API (c) LuaFFI (d) LuaJIT's
FFI. Taking the native Lua C API as the baseline, dyncall was (surprisingly) the worst (twice
as slow) and LuaJIT was (unsurprisingly) the fastest (50 times as fast!).
Lua also provides automatic memory management, although custom garbage
collection routines had to be written.

Data is stored in memory and, when necessary, is persisted (uncompressed) in
binary format to the file system. This allows us to quickly access data by
mmapp-ing the file.  Like kdb+ \cite{Borror2015}, one can think of Q as 
an in-memory database with persistent backing to the file system.

How efficient is the combination of Lua and C? 
On a sample workload, when the chunk size 
(discussed in Section~\ref{Vectors})
is set to 1M, the C code that does the real work
accounts for 92\% of the time, the run time takes 1\%, the balance attributable
to Lua as glue logic.
When the chunk size drops to 64K, C takes 52\%, the run time takes 2\% and Lua
the rest.

Q's software architecture consists of the following four layers. From bottom to
top with decreasing complexity, they are:
\be
\item The core run time system --- Vectors, Scalars, Reducers
\item operators --- provides core functionality (using C and OpenMP) on
  top of run time
\item Q library developers --- use Q and Lua to create higher level functions on
  top of core operators
\item Q programmers --- use Q much the way  Python programmer uses scikit-learn.
  \ee

\input{vectors}

\input{reducers}

\input{polymorphism}

% \input{glossary}
