\subsection{Vectors}
\label{Vectors}
A vector is essentially a map \(f(i)\) such that given \(i, 0 \leq i < n\), it
returns a value of a given type. The main types that \Q\ supports are four variants
of integers (1, 2, 4, and 8 byte) and two variations of floating point (single
and double precision). In addition, it supports bit vectors and constant length
strings. There is limited support for variable length strings, which are used
primarily as dictionaries. 

Note that \Q\ has 6 types of numbers, in contrast with Lua which uses a 
single type {\tt number}, internally a double precision floating point.
This is because data bandwidth plays a significant role in determining
performance, as illustrated by Nvidia's
introduction of half-precision floating point  \cite{nvidia2017}. The user is
encouraged (but not required) to use the smallest type that supports the actual
dynamic range required. 


When a vector is created, we need to specify (i) its type (ii) whether it has
null values (iii) how it will be populuated. We can either (a) ``push'' data to
it, much like writing to a file in append mode or (b) we can provide a generator
function, which generates a chunk at a time when invoked.
%% TODO Have not introduced chunk as yet

Vectors are evaluated lazily. Hence, a statement like 
{\tt x = Q.const(\{len = 10, qtype = I4, val = 0\})} does not actually create
ten
4-byte integers with value 0 as one might suspect. Data is populated only when
{\tt eval()} is explicity invoked on the vector or the data is 
implicitly required by some other operator e.g. {\tt Q.print\_csv(x)}

Vectors are processed in chunks. Consider an expression  like \(\sum (a + b\times
c)\), written in \Q\ as {\tt d = Q.sum(Q.add(Q.mul(b,c), a))}.
When {\tt d} is eval'd, computation alternates between the {\tt mul, add, sum}
operators
processing chunks of data at a time until there are
no more.
The chunk size, \(n_C\), is chosen large enough that it is amenable to
vectorization and parallelization and small enough that its memory consumption
is low.


Vectors are not mutable (with few exceptions)
and must be produced sequentially. In other words, the \(i^{th}\) element must
be produced before the \({i+1}^{th}\). Vectors
operate in ``chunks'' of a fixed size. Let us say that the chunk size is 64K and
that we have produced 65K elements. In that case, the current chunk would have
only 1K elements. Whether one can get access to an element in the previous chunk
depends on whether the vector has been ``memo-ized''. The default behavior, with
a concomitant performance hit, is to memo-ize. However, when the programmer is
aware that the vector will be consumed in a streaming fashion, they set memo
to false. 

Memo-izing is done by appending previous chunks in binary format to a file.
Subsequent reads of this vector are done by mmap-ing the file. Not all
algorithms are readily transformed into streaming operations e.g. sort. There
are a few cases where we support modifying a vector after it has been fully
materialized by opening it in write mode and mmap-ing it.

Mmap-ing gives us the illusion of a linear address space. This is useful to
incoporate algorithms and libraries that have not been written with streaming in
mind e.g., \Q\ borrows heavily from LAPACK when needed.

\Q's run time is an alternate approach to ``stream fusion''
\cite{Mainland2017}. In
that paper, the authors identify this as a technique that allows a compiler to
``cope with boxed numeric types, handle lazy evaluation, and
eliminate intermediate data structures''.
